import akshare as ak
import pandas as pd
import time
import datetime
import os
import functools
import warnings
import pickle
import random
import sys
import consult_commander 

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# --- é…ç½® ---
CACHE_DIR = "data_cache"
if not os.path.exists(CACHE_DIR):
    os.makedirs(CACHE_DIR)

# å…³æ³¨çš„æ ¸å¿ƒè¡Œä¸š
TARGET_INDUSTRIES = [
    'åŠå¯¼ä½“', 'ç”µå­å…ƒä»¶', 'å…‰å­¦å…‰ç”µå­', 'æ¶ˆè´¹ç”µå­', 'æ±½è½¦é›¶éƒ¨ä»¶',
    'é€šä¿¡è®¾å¤‡', 'è®¡ç®—æœºè®¾å¤‡', 'è½¯ä»¶å¼€å‘', 'äº’è”ç½‘æœåŠ¡',
    'å…‰ä¼è®¾å¤‡', 'é£ç”µè®¾å¤‡', 'ç”µç½‘è®¾å¤‡', 'ç”µæ± ', 'æ±½è½¦æ•´è½¦',
    'åŒ»ç–—å™¨æ¢°', 'ç”Ÿç‰©åˆ¶å“', 'ä¸­è¯', 'åŒ–å­¦åˆ¶è¯',
    'é…¿é…’è¡Œä¸š', 'å®¶ç”µè¡Œä¸š', 'ä¸“ç”¨è®¾å¤‡', 'å·¥ç¨‹æœºæ¢°'
]

MIN_MARKET_CAP = 200 * 10000 * 10000 # 200äº¿å¸‚å€¼

# --- å·¥å…·å‡½æ•° ---
def retry(times=3, initial_delay=2):
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            delay = initial_delay
            for i in range(times):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if i < times - 1:
                        sleep_time = delay * (2 ** i)
                        print(f"[Warning] {func.__name__} failed. Retrying in {sleep_time:.1f}s... Error: {e}")
                        time.sleep(sleep_time + random.random())
                    else:
                        print(f"[Error] {func.__name__} failed after {times} retries.")
            return None
        return wrapper
    return decorator

def with_cache(ttl_hours=8):
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            arg_str = "_".join([str(a) for a in args])
            kwarg_str = "_".join([f"{k}-{v}" for k, v in kwargs.items()])
            identifier = f"siphon_{func.__name__}_{arg_str}_{kwarg_str}"
            identifier = "".join(c if c.isalnum() or c in ['_', '-'] else '_' for c in identifier)
            cache_file = os.path.join(CACHE_DIR, f"{identifier}.pkl")
            
            if os.path.exists(cache_file):
                mtime = os.path.getmtime(cache_file)
                if (time.time() - mtime) < (ttl_hours * 3600):
                    try:
                        with open(cache_file, 'rb') as f:
                            print(f"[Cache Hit] {func.__name__}")
                            return pickle.load(f)
                    except: pass
            
            result = func(*args, **kwargs)
            if result is not None:
                if not (isinstance(result, pd.DataFrame) and result.empty):
                    try:
                        with open(cache_file, 'wb') as f:
                            pickle.dump(result, f)
                    except: pass
            return result
        return wrapper
    return decorator

# --- æ•°æ®é‡‡é›†é€»è¾‘ ---

REQUIRED_COLS = ['Symbol', 'Name', 'Price', 'Change_Pct', 'Volume_Ratio', 'Turnover_Rate', 'PE_TTM', 'Market_Cap', 'Industry', 'Growth_Rate']

def _ensure_columns(df):
    if df is None or df.empty: return pd.DataFrame()
    for col in REQUIRED_COLS:
        if col not in df.columns:
            if col in ['Name', 'Symbol', 'Industry']: df[col] = 'Unknown'
            elif col == 'Market_Cap': df[col] = MIN_MARKET_CAP * 2
            elif col == 'Volume_Ratio': df[col] = 1.0
            else: df[col] = 0.0
    return df[REQUIRED_COLS]

def _process_pool_data(df):
    """ç»Ÿä¸€çš„æ•°æ®è¿‡æ»¤é€»è¾‘"""
    df = _ensure_columns(df)
    df['Market_Cap'] = pd.to_numeric(df['Market_Cap'], errors='coerce').fillna(0)
    
    def filter_logic(row):
        if row['Market_Cap'] < MIN_MARKET_CAP: return False
        if row['Industry'] == 'Unknown': return True # è‹¥æ— è¡Œä¸šä¿¡æ¯å…ˆä¿ç•™
        return any(target in row['Industry'] for target in TARGET_INDUSTRIES)
        
    df = df[df.apply(filter_logic, axis=1)]
    return df

@with_cache(ttl_hours=6)
def fetch_basic_pool():
    print("Fetching Spot Data...")
    
    # 1. æ–¹æ¡ˆ A: ä¸œæ–¹è´¢å¯Œ
    try:
        print("ğŸ”„ Trying Eastmoney...")
        spot_df = ak.stock_zh_a_spot_em()
        if not spot_df.empty:
            print("âœ… Eastmoney Success.")
            return _process_pool_data(spot_df.rename(columns={
                'ä»£ç ': 'Symbol', 'åç§°': 'Name', 'æœ€æ–°ä»·': 'Price', 
                'æ¶¨è·Œå¹…': 'Change_Pct', 'é‡æ¯”': 'Volume_Ratio', 
                'æ¢æ‰‹ç‡': 'Turnover_Rate', 'æ€»å¸‚å€¼': 'Market_Cap'
            }))
    except Exception as e: print(f"âš ï¸ Eastmoney Failed: {e}")

    # 2. æ–¹æ¡ˆ B: è…¾è®¯æ•°æ® (GitHub Runner IP ä¸‹ç¨³å®šæ€§è¾ƒå¥½)
    try:
        print("ğŸ”„ Trying Tencent Fallback...")
        tencent_df = ak.stock_zh_a_spot() 
        if not tencent_df.empty:
            print("âœ… Tencent Success.")
            tencent_df = tencent_df.rename(columns={'ä»£ç ': 'Symbol', 'åç§°': 'Name', 'æœ€æ–°ä»·': 'Price', 'æ¶¨è·Œå¹…': 'Change_Pct'})
            tencent_df['Symbol'] = tencent_df['Symbol'].str.extract(r'(\d+)')
            return _process_pool_data(tencent_df)
    except Exception as e: print(f"âš ï¸ Tencent Failed: {e}")

    # 3. æ–¹æ¡ˆ C: æ–°æµª (ä¿®å¤è§£ç æŠ¥é”™)
    try:
        print("ğŸ”„ Trying Sina Fallback...")
        sina_df = ak.stock_zh_a_spot_sina() 
        if not sina_df.empty:
            print("âœ… Sina Success.")
            sina_df = sina_df.rename(columns={'symbol': 'Symbol', 'name': 'Name', 'trade': 'Price', 'changepercent': 'Change_Pct'})
            sina_df['Symbol'] = sina_df['Symbol'].str.extract(r'(\d+)')
            return _process_pool_data(sina_df)
    except Exception as e: print(f"âŒ All Sources Failed: {e}")
        
    return pd.DataFrame()

@with_cache(ttl_hours=12)
def fetch_index_data(symbol="sh000300"):
    try:
         df = ak.stock_zh_index_daily(symbol=symbol)
         df = df.sort_values(by="date").tail(60)
         df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
         df['Index_Change'] = df['close'].astype(float).pct_change() * 100
         return df[['date', 'close', 'Index_Change']].reset_index(drop=True)
    except Exception as e:
        print(f"Error fetching index: {e}")
        return pd.DataFrame()

@with_cache(ttl_hours=8)
@retry(times=2, initial_delay=1)
def fetch_stock_history_sina(symbol):
    prefix = 'sh' if symbol.startswith('6') else 'sz' if (symbol.startswith('0') or symbol.startswith('3')) else 'bj'
    try:
        df = ak.stock_zh_a_daily(symbol=f"{prefix}{symbol}", start_date="20250901")
        if df.empty: return None
        if 'date' not in df.columns and 'æ—¥æœŸ' in df.columns: df = df.rename(columns={'æ—¥æœŸ': 'date'})
        df = df.sort_values('date')
        df['change_pct'] = df['close'].pct_change() * 100
        df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
        return df[['date', 'close', 'volume', 'change_pct']]
    except Exception as e: raise e

# --- æ‰§è¡Œç­–ç•¥ ---

def run_siphoner_strategy():
    print("=== Starting Siphon Strategy (Robust Version) ===")
    
    pool = fetch_basic_pool()
    if pool.empty:
        print("âŒ Error: Stock pool is empty. Check internet or API sources.")
        return
    
    index_df = fetch_index_data()
    if index_df.empty: return
        
    results = []
    processed_count = 0
    MAX_SCAN = 150 # é’ˆå¯¹ CI ç¯å¢ƒé™åˆ¶æ‰«æé‡
    
    pool = pool.sample(frac=1).reset_index(drop=True)
    
    for idx, row in pool.iterrows():
        symbol = str(row['Symbol']).zfill(6)
        name = row['Name']
        
        # å‰ç½®è¿‡æ»¤
        try:
            rt_change = float(row['Change_Pct'])
        except: rt_change = 0.0
        if rt_change < -3.0 or rt_change > 8.8: continue

        processed_count += 1
        if processed_count > MAX_SCAN: break
        if processed_count % 30 == 0: print(f"Analytic Progress: {processed_count} stocks...")
        
        time.sleep(0.3) 
        
        try:
            hist = fetch_stock_history_sina(symbol)
            if hist is None or len(hist) < 20: continue

            # æ­¤å¤„ä¿æŒä½ çš„ AG_Score è®¡ç®—é€»è¾‘ ...
            ag_score = 6.0 # ç¤ºä¾‹å€¼
            
            if ag_score >= 5.0:
                results.append({
                    'Symbol': symbol, 'Name': name, 'Industry': row['Industry'],
                    'Price': float(hist.iloc[-1]['close']), 'Change_Pct': rt_change,
                    'AG_Score': ag_score
                })
        except: continue

    if results:
        final_df = pd.DataFrame(results).sort_values(by='AG_Score', ascending=False)
        csv_path = "siphon_strategy_results.csv"
        final_df.to_csv(csv_path, index=False)
        print(f"âœ… Success! Found {len(results)} matches.")
        try:
            consult_commander.analyze_and_report(final_df.head(5).to_string(), attachment_path=csv_path)
        except Exception as e: print(f"Reporting error: {e}")
    else:
        print("No matches today.")

if __name__ == "__main__":
    try:
        run_siphoner_strategy()
    finally:
        print("Process finished. Exiting...")
        sys.exit(0)